#!/usr/bin/env python3
"""Creative Tools Module

This module provides creative media tools including:
- Video montage generator
- Photo slideshow creator
- Video clip extractor
- AI-powered thumbnail suggestions
"""

import os
import subprocess
import logging
from typing import List, Dict, Any, Optional, Tuple
from pathlib import Path
import tempfile
from dotenv import load_dotenv
from utils.db_utils_vector import get_db_connection
import httpx

load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

TWELVE_LABS_API_KEY = os.getenv('TWELVE_LABS_API_KEY')
TWELVE_LABS_API_URL = "https://api.twelvelabs.io/v1.2"


class VideoMontageGenerator:
    """Create video montages from multiple clips"""
    
    def __init__(self, output_dir: str = None):
        self.output_dir = output_dir or tempfile.gettempdir()
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
    def create_montage(self, video_clips: List[Dict[str, Any]], 
                      output_filename: str,
                      transition: str = "fade",
                      duration_per_clip: float = 5.0,
                      add_music: bool = False,
                      music_file: str = None) -> Dict[str, Any]:
        """Create a video montage from multiple clips
        
        Args:
            video_clips: List of dicts with 'file_path', 'start_time', 'end_time'
            output_filename: Name for output montage file
            transition: Transition type ('fade', 'dissolve', 'wipe')
            duration_per_clip: Max duration for each clip in seconds
            add_music: Whether to add background music
            music_file: Path to music file (if add_music=True)
            
        Returns:
            Dict with success status and output file path
        """
        try:
            output_path = os.path.join(self.output_dir, output_filename)
            
            # Create a text file with input clips for ffmpeg
            concat_file = os.path.join(self.output_dir, "concat_list.txt")
            processed_clips = []
            
            logger.info(f"ðŸŽ¬ Creating montage with {len(video_clips)} clips")
            
            # Extract and process each clip
            for i, clip in enumerate(video_clips):
                clip_output = os.path.join(self.output_dir, f"clip_{i}.mp4")
                
                # Extract clip segment
                start_time = clip.get("start_time", 0)
                duration = min(
                    clip.get("end_time", start_time + duration_per_clip) - start_time,
                    duration_per_clip
                )
                
                cmd = [
                    "ffmpeg", "-y",
                    "-i", clip["file_path"],
                    "-ss", str(start_time),
                    "-t", str(duration),
                    "-c:v", "libx264",
                    "-c:a", "aac",
                    "-strict", "experimental",
                    clip_output
                ]
                
                subprocess.run(cmd, check=True, capture_output=True)
                processed_clips.append(clip_output)
                
                logger.info(f"  âœ“ Processed clip {i+1}/{len(video_clips)}")
            
            # Create concat file
            with open(concat_file, 'w') as f:
                for clip_path in processed_clips:
                    f.write(f"file '{clip_path}'\n")
            
            # Concatenate clips with transitions
            if transition == "fade":
                # Use xfade filter for smooth transitions
                self._create_with_fade(processed_clips, output_path, add_music, music_file)
            else:
                # Simple concatenation
                concat_cmd = [
                    "ffmpeg", "-y",
                    "-f", "concat",
                    "-safe", "0",
                    "-i", concat_file,
                    "-c", "copy",
                    output_path
                ]
                subprocess.run(concat_cmd, check=True, capture_output=True)
            
            # Cleanup temporary files
            for clip_path in processed_clips:
                os.remove(clip_path)
            os.remove(concat_file)
            
            logger.info(f"âœ… Montage created: {output_path}")
            
            return {
                "success": True,
                "output_path": output_path,
                "duration": len(video_clips) * duration_per_clip,
                "num_clips": len(video_clips)
            }
            
        except Exception as e:
            logger.error(f"âŒ Error creating montage: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def _create_with_fade(self, clips: List[str], output_path: str,
                         add_music: bool = False, music_file: str = None):
        """Create montage with fade transitions"""
        # For simplicity, use basic concat - xfade requires complex filter graphs
        concat_file = os.path.join(self.output_dir, "concat_fade.txt")
        
        with open(concat_file, 'w') as f:
            for clip_path in clips:
                f.write(f"file '{clip_path}'\n")
        
        cmd = [
            "ffmpeg", "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", concat_file,
            "-c:v", "libx264",
            "-preset", "medium",
            "-crf", "23",
            "-c:a", "aac",
            output_path
        ]
        
        if add_music and music_file:
            # Add background music
            cmd = [
                "ffmpeg", "-y",
                "-f", "concat",
                "-safe", "0",
                "-i", concat_file,
                "-i", music_file,
                "-c:v", "libx264",
                "-c:a", "aac",
                "-shortest",  # Stop when shortest input ends
                output_path
            ]
        
        subprocess.run(cmd, check=True, capture_output=True)
        os.remove(concat_file)


class SlideshowCreator:
    """Create video slideshows from photos"""
    
    def __init__(self, output_dir: str = None):
        self.output_dir = output_dir or tempfile.gettempdir()
        Path(self.output_dir).mkdir(parents=True, exist_ok=True)
        
    def create_slideshow(self, photo_paths: List[str],
                        output_filename: str,
                        duration_per_photo: float = 3.0,
                        transition: str = "fade",
                        add_music: bool = False,
                        music_file: str = None,
                        resolution: Tuple[int, int] = (1920, 1080)) -> Dict[str, Any]:
        """Create a video slideshow from photos
        
        Args:
            photo_paths: List of paths to photo files
            output_filename: Name for output video file
            duration_per_photo: Display duration for each photo
            transition: Transition effect ('fade', 'slide', 'zoom')
            add_music: Whether to add background music
            music_file: Path to music file
            resolution: Output video resolution (width, height)
            
        Returns:
            Dict with success status and output file path
        """
        try:
            output_path = os.path.join(self.output_dir, output_filename)
            
            logger.info(f"ðŸ“¸ Creating slideshow with {len(photo_paths)} photos")
            
            # Create temporary video clips from each photo
            temp_clips = []
            for i, photo_path in enumerate(photo_paths):
                clip_output = os.path.join(self.output_dir, f"photo_clip_{i}.mp4")
                
                # Convert photo to video clip
                cmd = [
                    "ffmpeg", "-y",
                    "-loop", "1",
                    "-i", photo_path,
                    "-t", str(duration_per_photo),
                    "-vf", f"scale={resolution[0]}:{resolution[1]}:force_original_aspect_ratio=decrease,pad={resolution[0]}:{resolution[1]}:(ow-iw)/2:(oh-ih)/2",
                    "-c:v", "libx264",
                    "-pix_fmt", "yuv420p",
                    clip_output
                ]
                
                subprocess.run(cmd, check=True, capture_output=True)
                temp_clips.append(clip_output)
                
                logger.info(f"  âœ“ Processed photo {i+1}/{len(photo_paths)}")
            
            # Concatenate clips
            concat_file = os.path.join(self.output_dir, "slideshow_concat.txt")
            with open(concat_file, 'w') as f:
                for clip_path in temp_clips:
                    f.write(f"file '{clip_path}'\n")
            
            # Build final slideshow
            cmd = [
                "ffmpeg", "-y",
                "-f", "concat",
                "-safe", "0",
                "-i", concat_file,
                "-c:v", "libx264",
                "-preset", "medium",
                "-crf", "23"
            ]
            
            # Add music if requested
            if add_music and music_file:
                cmd.extend(["-i", music_file, "-c:a", "aac", "-shortest"])
            
            cmd.append(output_path)
            
            subprocess.run(cmd, check=True, capture_output=True)
            
            # Cleanup
            for clip_path in temp_clips:
                os.remove(clip_path)
            os.remove(concat_file)
            
            total_duration = len(photo_paths) * duration_per_photo
            logger.info(f"âœ… Slideshow created: {output_path} ({total_duration}s)")
            
            return {
                "success": True,
                "output_path": output_path,
                "duration": total_duration,
                "num_photos": len(photo_paths),
                "resolution": resolution
            }
            
        except Exception as e:
            logger.error(f"âŒ Error creating slideshow: {str(e)}")
            return {"success": False, "error": str(e)}


class ClipExtractor:
    """Extract specific segments from videos"""
    
    def extract_clip(self, video_path: str, start_time: float, end_time: float,
                    output_filename: str, output_dir: str = None) -> Dict[str, Any]:
        """Extract a clip from a video
        
        Args:
            video_path: Path to source video
            start_time: Start time in seconds
            end_time: End time in seconds
            output_filename: Name for extracted clip
            output_dir: Output directory (default: temp)
            
        Returns:
            Dict with success status and clip info
        """
        try:
            output_dir = output_dir or tempfile.gettempdir()
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            output_path = os.path.join(output_dir, output_filename)
            
            duration = end_time - start_time
            
            logger.info(f"âœ‚ï¸ Extracting clip: {start_time}s - {end_time}s ({duration}s)")
            
            # Extract clip with re-encoding for accuracy
            cmd = [
                "ffmpeg", "-y",
                "-i", video_path,
                "-ss", str(start_time),
                "-t", str(duration),
                "-c:v", "libx264",
                "-c:a", "aac",
                "-strict", "experimental",
                output_path
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            
            # Get file size
            file_size = os.path.getsize(output_path)
            
            logger.info(f"âœ… Clip extracted: {output_path} ({file_size/1024/1024:.2f} MB)")
            
            return {
                "success": True,
                "output_path": output_path,
                "start_time": start_time,
                "end_time": end_time,
                "duration": duration,
                "file_size_mb": file_size / 1024 / 1024
            }
            
        except Exception as e:
            logger.error(f"âŒ Error extracting clip: {str(e)}")
            return {"success": False, "error": str(e)}
    
    def extract_multiple_clips(self, video_path: str, 
                              time_ranges: List[Tuple[float, float]],
                              output_dir: str = None) -> Dict[str, Any]:
        """Extract multiple clips from a single video
        
        Args:
            video_path: Path to source video
            time_ranges: List of (start_time, end_time) tuples
            output_dir: Output directory
            
        Returns:
            Dict with list of extracted clips
        """
        clips = []
        
        for i, (start, end) in enumerate(time_ranges):
            output_name = f"clip_{i+1}_{start:.0f}_{end:.0f}.mp4"
            result = self.extract_clip(video_path, start, end, output_name, output_dir)
            
            if result["success"]:
                clips.append(result)
        
        return {
            "success": True,
            "num_clips": len(clips),
            "clips": clips
        }


class ThumbnailSuggester:
    """Suggest best thumbnail frames using AI analysis"""
    
    def __init__(self, api_key: str = None):
        self.api_key = api_key or TWELVE_LABS_API_KEY
        self.base_url = TWELVE_LABS_API_URL
        
    async def suggest_thumbnails(self, video_id: str, 
                                num_suggestions: int = 5) -> Dict[str, Any]:
        """Suggest best frames for video thumbnail
        
        Args:
            video_id: TwelveLabs video ID
            num_suggestions: Number of thumbnail suggestions
            
        Returns:
            Dict with suggested timestamps for thumbnails
        """
        try:
            async with httpx.AsyncClient(timeout=60.0) as client:
                # Get video chapters to find key moments
                response = await client.post(
                    f"{self.base_url}/generate",
                    headers={
                        "x-api-key": self.api_key,
                        "Content-Type": "application/json"
                    },
                    json={
                        "video_id": video_id,
                        "types": ["chapter", "highlight"]
                    }
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Extract key timestamps from chapters and highlights
                    suggestions = []
                    
                    # Get chapter start times
                    chapters = data.get("chapters", [])
                    for chapter in chapters[:num_suggestions]:
                        suggestions.append({
                            "timestamp": chapter.get("start", 0),
                            "reason": "Chapter start",
                            "description": chapter.get("chapter_title", "")
                        })
                    
                    # Get highlight timestamps
                    highlights = data.get("highlights", [])
                    for highlight in highlights[:num_suggestions]:
                        suggestions.append({
                            "timestamp": highlight.get("start", 0),
                            "reason": "Key moment",
                            "description": highlight.get("highlight", "")
                        })
                    
                    # Sort by timestamp and limit
                    suggestions = sorted(suggestions, key=lambda x: x["timestamp"])[:num_suggestions]
                    
                    logger.info(f"âœ… Generated {len(suggestions)} thumbnail suggestions")
                    
                    return {
                        "success": True,
                        "video_id": video_id,
                        "suggestions": suggestions
                    }
                else:
                    logger.error(f"âŒ Failed to generate suggestions: {response.text}")
                    return {"success": False, "error": response.text}
                    
        except Exception as e:
            logger.error(f"âŒ Error generating thumbnail suggestions: {str(e)}")
            return {"success": False, "error": str(e)}


# Convenience functions
def create_video_montage(clips: List[Dict], output_name: str, **kwargs) -> Dict[str, Any]:
    """Create a video montage"""
    generator = VideoMontageGenerator()
    return generator.create_montage(clips, output_name, **kwargs)


def create_photo_slideshow(photos: List[str], output_name: str, **kwargs) -> Dict[str, Any]:
    """Create a photo slideshow"""
    creator = SlideshowCreator()
    return creator.create_slideshow(photos, output_name, **kwargs)


def extract_video_clip(video_path: str, start: float, end: float, 
                      output_name: str, **kwargs) -> Dict[str, Any]:
    """Extract a video clip"""
    extractor = ClipExtractor()
    return extractor.extract_clip(video_path, start, end, output_name, **kwargs)


async def suggest_video_thumbnails(video_id: str, num: int = 5) -> Dict[str, Any]:
    """Suggest thumbnail frames for a video"""
    suggester = ThumbnailSuggester()
    return await suggester.suggest_thumbnails(video_id, num)


if __name__ == "__main__":
    import asyncio
    
    print("ðŸŽ¨ Creative Tools Module")
    print("=" * 50)
    
    # Example usage
    print("\n1. Video Montage Generator - Ready")
    print("2. Photo Slideshow Creator - Ready")
    print("3. Clip Extractor - Ready")
    print("4. Thumbnail Suggester - Ready")
    
    print("\nâœ… All creative tools initialized successfully!")
